<!doctype html>
<html lang='en'>
  <head>
    <meta name='twitter:card' content='summary' />
    <meta property='og:title' content='Lane detection using Kotlin and OpenCV' />
    <meta property='og:url' content='https://seansoper.com/blog/lane_detection_opencv_kotlin.html' />
    <meta property='og:description' content='In terms of hard problems in computer science, computer vision ranks up there as one of the toughest. Fortunately we have access to tools like OpenCV which comes pre-packaged with solutions for common problems like reading in a video feed or converting a color space. And thanks to native Java bindings, it is available for us to use in Kotlin.' />
    <meta property='og:image' content='//source.unsplash.com/sFk4YBGIwaQ/1200x627' />
    <!-- Generated by zebec https://github.com/ssoper/Zebec -->
    <meta charset='utf-8' />
    <meta http-equiv='X-UA-Compatible' content='IE=edge' />
    <meta name='viewport' content='width=device-width, initial-scale=1, shrink-to-fit=no' />
    <meta name='ICBM' content='39.0840, 77.1528' />
    <title>eat. code. stocks.</title>
    <link type='image/x-icon' href='/favicon.ico' rel='shortcut icon' />
    <link type='application/rss+xml' title='eat. code. stocks.' href='/blog/rss.xml' rel='alternate' />
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src='https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js'></script>
      <script src='https://oss.maxcdn.com/respond/1.4.2/respond.min.js'></script>
    <![endif]-->
  </head>
  <body>
    <!-- Navigation -->
    <nav class='navbar navbar-expand-lg navbar-dark bg-dark fixed-top'>
      <div class='container'>
        <a class='navbar-brand' title='eat. code. stocks.' href='/blog'>üç± üë®üèª‚Äçüíª üè¶</a>
        <button class='navbar-toggler' type='button' data-toggle='collapse' data-target='#navbarResponsive' aria-controls='navbarResponsive' aria-expanded='false' aria-label='Toggle navigation'>
          <span class='navbar-toggler-icon'></span>
        </button>
        <div class='collapse navbar-collapse' id='navbarResponsive'>
          <ul class='navbar-nav ml-auto'>
            <li class='nav-item'>
              <a class='nav-link' href='/'>Home</a>
            </li>
            <li class='nav-item'>
              <a class='nav-link' href='/blog'>Blog</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>
    <!-- Page Content -->
    <div class='container'>
      <div class='row'>
        <div class='col-lg-8 content'>
          <h1 class='mt-4'>Lane detection using Kotlin and OpenCV</h1><h2 class='subtitle'>Using computer vision to detect highway markings in real-time</h2><div class='author'>
  <img src='/images/avatar_normal.jpg' alt='' srcset='/images/avatar_normal.jpg 1x, /images/avatar_retina.jpg 2x'/>
  <ul>
    <li>Sean Soper</li>
    <li>June 22, 2021</li>
  </ul>
</div><img class='img-fluid rounded' alt='' src='//source.unsplash.com/sFk4YBGIwaQ/900x300' srcset='//source.unsplash.com/sFk4YBGIwaQ/900x300 1x, //source.unsplash.com/sFk4YBGIwaQ/1800x600 2x'><p>In terms of hard problems in computer science, computer vision <a href="https://medium.com/@CharlesOllion/whats-easy-hard-in-ai-computer-vision-these-days-e7679b9f7db7">ranks up there</a> as one of the toughest. Fortunately we have access to tools like <a href="https://opencv.org/">OpenCV</a> which comes pre-packaged with solutions for common problems like reading in a video feed or converting a color space. And thanks to native Java bindings, it is available for us to use in Kotlin.</p><h2>Problem Set</h2><p>Roughly speaking, we can break our problem down into the following steps.</p><ol><li>Read in each frame of a video as an image.</li><li>Use <a href="https://docs.opencv.org/3.4/da/d22/tutorial_py_canny.html">Canny Edge Detection</a> to retrieve a version of the image with only edges showing.</li><li>Mask the parts of the image that you need which in our case is directly front and center of the driver.</li><li>Use the <a href="https://docs.opencv.org/3.4/d9/db0/tutorial_hough_lines.html">Hough Line Transform</a> to detect straight lines of a minimum length.</li><li>With a polynomial curve fitter, average out the detected lines into one left and one right line.</li><li>Overlay those lines onto the original video.</li></ol><h2>Tools</h2><p>In addition to OpenCV, we‚Äôll also need to bring in the math package from the Apache Commons library. Note that there are several Java-friendly versions of OpenCV floating around in the Maven repository. We opted for the one hosted by <a href="https://github.com/openpnp/opencv">OpenPnP</a>.</p><pre><code>
dependencies {
  implementation(&quot;org.openpnp:opencv:4.5.1-2&quot;)
  implementation(&quot;org.apache.commons:commons-math3:3.6.1&quot;)
}
</code></pre><h2>Frame By Frame</h2><p>Let‚Äôs open our input file using OpenCV‚Äôs built-in tools, read it frame by frame and pass each of those frames through our process outlined above to pull out the necessary data. To watch it in real-time, we will use <a href="https://en.wikipedia.org/wiki/Swing_(Java)">Java Swing</a> to create a window that will display each frame as it is processed.</p><pre><code>
val image = Mat()
val input = VideoCapture(inputFilePath)
val size = Size(input.get(Videoio.CAP_PROP_FRAME_WIDTH),input.get(Videoio.CAP_PROP_FRAME_HEIGHT))

// Setup the Swing window
val videoPanel = JLabel()
val frame = HighGui.createJFrame(&quot;output&quot;, HighGui.WINDOW_AUTOSIZE)
frame.defaultCloseOperation = EXIT_ON_CLOSE
frame.setSize(size.width.toInt(), size.height.toInt())
frame.contentPane = videoPanel
frame.isVisible = true

while (input.read(image)) {
  // do stuff
}
</code></pre><img src="/images/blog/lane_detection_opencv_kotlin/step1.jpg" alt="Step 1" class="img-fluid rounded embedded">
<h2>Edge Detection</h2><p>Before we can apply our edge detection, we‚Äôll need to do some clean up on our image. Specifically, we need to convert it to grayscale and then apply a 5x5 Gaussian blur filter to reduce the amount of noise. These steps will optimize for the edge detection algorithm. Note that a <code>Mat</code> is the type of object in which complex data, such as an image, is represented in OpenCV. It is a multi-dimensional array that <a href="https://docs.opencv.org/3.4/d6/d6d/tutorial_mat_the_basic_image_container.html">stores information</a> about each pixel.</p><pre><code>
fun getEdges(source: Mat): Mat {
    val gray = Mat()
    cvtColor(source, gray, COLOR_RGB2GRAY)
    
    val blur = Mat()
    GaussianBlur(gray, blur, Size(5.0, 5.0), 0.0)
    
    val dest = Mat()
    Canny(blur, dest, 50.0, 150.0)
    
    return dest
}
</code></pre><p>Our original image is read in as a <code>Mat</code>, converted to grayscale, filtered with a Gaussian blur and then has a Canny Edge Detector applied to it, the result of which is stored in <code>dest</code> and returned.</p><img src="/images/blog/lane_detection_opencv_kotlin/step2.png" alt="Step 2" class="img-fluid rounded embedded">
<h2>‚ÄúWear The Damn Mask‚Äù</h2><p><a href="https://www.mymcmedia.org/rockville-brewery-pays-tribute-to-gov-hogan-with-its-latest-beer/">Maryland pandemic jokes</a> aside, we need to apply a mask to our image to cut out the parts that we don‚Äôt need. Without this mask, our line detector would be detecting lines such as the overhead freeway signs, other cars, etc. We just need to focus on the area immediately in front of the vehicle.</p><p>When deciding the shape and size of a mask in a <code>Mat</code> we need to consider the coordinate system. Typically, the <code>x</code> and <code>y</code> coordinates run up and to the right but in a <code>Mat</code>, they go down and to the right.</p><pre><code>
  x ‚Üí
y 0 1 2 3 4 5
‚Üì 1
  2
  3
  4
  5
</code></pre><p>Using this coordinate system, we will draw a trapezoid which captures this space in front of the vehicle. We will then create a mask filled with zeroes and use a <code>bitwise_and</code> against that mask to slice out the part of the image that we need.</p><pre><code>
    fun getSlice(source: Mat): Mat {
        val height = source.height().toDouble()
        val width = source.width().toDouble()
      
        val polygons: List&lt;MatOfPoint&gt; = listOf(
            MatOfPoint(
                Point(175.0, height), // bottom left
                Point(450.0, 400.0),  // top left
                Point(900.0, 400.0),  // top right
                Point(width, height)  // bottom right
            )
        )
      
        val mask = Mat.zeros(source.rows(), source.cols(), 0)
        fillPoly(mask, polygons, Scalar(255.0))
      
        val dest = Mat()
        bitwise_and(source, mask, dest)
      
        return dest
    }
</code></pre><img src="/images/blog/lane_detection_opencv_kotlin/step3.png" alt="Step 3" class="img-fluid rounded embedded">
<h2>Visualize Success</h2><p>With our mask in place we can now use a probalistic Hough line transform to try and guess where the straight lines are. We then average them out using a <a href="https://commons.apache.org/proper/commons-math/javadocs/api-3.3/org/apache/commons/math3/fitting/PolynomialCurveFitter.html">polynomial curve fitter</a> to retrieve the slope and y-intercept co-efficients.</p><pre><code>
fun getLines(source: Mat): Pair&lt;HoughLine, HoughLine&gt; {
    val lines = Mat()
    HoughLinesP(source, lines,2.0, Math.PI/180, 100, 100.0, 50.0)
    
    val left = HoughLine(source)
    val right = HoughLine(source)
    
    for (row in 0 until lines.rows()) {
        val points: DoubleArray = lines.get(row, 0)
        val weighted = WeightedObservedPoints()
        val fitter = PolynomialCurveFitter.create(1)
        
        weighted.add(points[0], points[1])
        weighted.add(points[2], points[3])
        
        val fitted = fitter.fit(weighted.toList())
        val slope = fitted[1]
        
        if (slope &lt; 0) {
            left.add(fitted)
        } else {
            right.add(fitted)
        }
    }
    
    return Pair(left, right)
}
</code></pre><p>If you recall from your high school geometry class, given a slope, y-intercept, and <code>y</code> value,  you can calculate the value of <code>x</code>.</p><pre><code>
y = mx + b
</code></pre><p>We know the <code>y</code> values since they will match up with the <code>y</code> values of the trapezoid we drew. So that means we need to calculate the values of <code>x</code>.</p><pre><code>
x = (y - b) / m
</code></pre><p>In our <code>HoughLine</code> class we have the following code to get the value of <code>x</code></p><pre><code>
  val coordinates: Pair&lt;Point, Point&gt;
      get() {
          val y1 = source.height()
          
          return Pair(
              Point((y1-yInterceptAvg)/slopeAvg, y1.toDouble()),
              Point((y1-150-yInterceptAvg)/slopeAvg, y1.toDouble()-150)
          )
      }
</code></pre><p>With  the coordinates of the detected lines in hand, let‚Äôs draw them on the original image from the video. We can make them really stand out by drawing them as thick bright green lines.</p><pre><code>
fun visualize(source: Mat, lines: Pair&lt;HoughLine, HoughLine&gt;): Mat {
    val grey = Mat.zeros(source.rows(), source.cols(), 0)
    val dest = Mat()
    cvtColor(grey, dest, COLOR_GRAY2RGB)
    
    val color = Scalar(0.0, 255.0, 0.0)
    line(dest, lines.first.coordinates.first, lines.first.coordinates.second, color, LINE_8)
    line(dest, lines.second.coordinates.first, lines.second.coordinates.second, color, LINE_8)
    
    val done = Mat()
    addWeighted(source, 0.9, dest, 1.0, 1.0, done)
    
    return done
}
</code></pre><img src="/images/blog/lane_detection_opencv_kotlin/step4.jpg" alt="Step 4" class="img-fluid rounded embedded">
<h2>Conclusion</h2><p>With all the required functionality now written out, let‚Äôs update our <code>while</code> loop to make use of it.</p><pre><code>
while (input.read(image)) {
    val canny = getEdges(image)
    val slice = getSlice(canny)
    val lines = getLines(slice)
    val visualized = visualize(image, lines)
    
    videoPanel.icon = ImageIcon(HighGui.toBufferedImage(visualized))
    videoPanel.repaint()
}
</code></pre><img src="/images/blog/lane_detection_opencv_kotlin/demo.gif" alt="Demo" class="rounded img-fluid embedded">
<h2>Conclusion</h2><p>I‚Äôve been fascinated with computer vision for a long time but these two <a href="https://towardsdatascience.com/tutorial-build-a-lane-detector-679fd8953132">amazing</a> <a href="https://www.analyticsvidhya.com/blog/2020/05/tutorial-real-time-lane-detection-opencv/">articles</a>, both written in Python using NumPy, inspired me to finally write a Kotlin version. The former article also does a much better job of explaining the math under the hood of OpenCV. While Kotlin doesn‚Äôt yet have quite the breadth and interoperability that NumPy does, efforts are <a href="https://kotlinlang.org/docs/data-science-overview.html#kotlin-libraries">underway</a> to get there. It‚Äôs an exciting time to be a part of this community and I‚Äôm eager to see new developments in computer vision in Kotlin.</p><p>The full code for this post can be found <a href="https://github.com/ssoper/lane-detector/releases/tag/1.0.0">here</a>.</p>
        </div>
        <!-- Sidebar Widgets Column -->
        <div class='col-md-4'>
          <!-- Search Widget -->
          <div class='card my-4'>
            <h5 class='card-header'>Search</h5>
            <div class='card-body'>
              <div class='input-group'>
                <input class='form-control' placeholder='Search for‚Ä¶' id='search-query' type='text' />
                <span class='input-group-btn'>
                  <button class='btn btn-secondary' type='button' id='search-button'>Go!</button>
                </span>
              </div>
            </div>
          </div>
          <a href='/blog/rss.xml'><img width='72' src='https://shields.io/badge/rss-2.0-blue?logo=rss'></a>
        </div>
      </div>
    </div>
    <!-- jQuery -->
    <script integrity='sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n' crossorigin='anonymous' src='https://code.jquery.com/jquery-3.4.1.slim.min.js'></script>
    <!-- Popper -->
    <script integrity='sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo' crossorigin='anonymous' src='https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js'></script>
    <!-- Bootstrap -->
    <script integrity='sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6' crossorigin='anonymous' src='https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js'></script>
    <!-- highlight.js -->
    <script src='//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/highlight.min.js'></script>
    <!-- Delay loading of some assets for Google PageSpeed optimizations -->
    <noscript id='deferred-styles'>
      <link href='https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css' integrity='sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh' crossorigin='anonymous' rel='stylesheet' />
      <link href='/css/blog.min.css' rel='stylesheet' />
      <link href='//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/styles/default.min.css' rel='stylesheet' />
    </noscript>
    <script src='/js/load_deferred_styles.min.js'></script>
    <script src='/js/load_highlight.min.js'></script>
    <script src='/js/load_search.min.js'></script>
    <!-- Google Analytics -->
    <script async src='https://www.googletagmanager.com/gtag/js?id=G-N2516DN82V'></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-N2516DN82V');
    </script>
  </body>
</html>